{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project: Continuum Suppression**\n"
      ],
      "metadata": {
        "id": "GBxaXUpYFnn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Members:\n",
        "\n",
        "1. Rajesh (MS20062)\n",
        "2. Govind Sharma (MS20053)\n",
        "3. Aniket Kumar (MS20189)\n",
        "4. Palak Meena\t(MS21005)"
      ],
      "metadata": {
        "id": "wC3r20FzI1l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data used can be accessed here: https://drive.google.com/file/d/1z4XnTmt3DPDITjZ-0P5blMmWLeNQF9YP/view?usp=sharing"
      ],
      "metadata": {
        "id": "G6c1_l1hGDDY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGVYDtnDnHXa"
      },
      "source": [
        "## Using CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sIe-W-SPVTXS"
      },
      "outputs": [],
      "source": [
        "# last column = 61\n",
        "#starting column = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PCA"
      ],
      "metadata": {
        "id": "Gi7N5x5dbuln"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgNI3I55ViSV",
        "outputId": "ef3c5f48-180c-4739-cca7-ec9538a2be86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "!pip install xgboost\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from xgboost import plot_tree\n",
        "!pip install graphviz\n",
        "import graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqjxqTVjV-_w",
        "outputId": "9d1bc6e9-a9dc-4db1-a263-ec43bb3477eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Access files in Google Drive\n",
        "file_path = '/content/drive/MyDrive/data_hep.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LNSz8jE8Vi9D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Use pandas to read the CSV file into a DataFrame\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MTIRC9s7XWGa"
      },
      "outputs": [],
      "source": [
        "# Define a function to apply to each element in the column\n",
        "def update_values(value):\n",
        "    if value in [0, 1]:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Apply the function to the specified column\n",
        "column_index = 60\n",
        "df.iloc[:, column_index] = df.iloc[:, column_index].apply(update_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzhON9niYdca",
        "outputId": "2bfce3f0-6fde-4231-f293-2b46c62acb57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of 0s and 1s in the 61st column:\n",
            "0    35765\n",
            "1    34841\n",
            "Name: type, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "counts = df.iloc[:, 60].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(\"Count of 0s and 1s in the 61st column:\")\n",
        "print(counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R6_RdI3nYd1n"
      },
      "outputs": [],
      "source": [
        "# Here 0 represents signal and 1 represents noise or background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4jDqRON0Y62M"
      },
      "outputs": [],
      "source": [
        "# Shuffle all rows\n",
        "shuffled_df = df.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a5Ne_94ZZjc",
        "outputId": "24a3057a-9c0d-487e-dd47-d1eeb97a058d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60606, 59)\n",
            "y_train shape: (60606,)\n",
            "X_test shape: (10000, 59)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Extract features (X) and labels (y) for the entire dataset\n",
        "X = df.iloc[:, 1:60]  # Features from columns 1 to 59, excluding the first column\n",
        "y = df.iloc[:, 60]    # Labels from the 61st column\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=10000, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SSAERMvma2Ll"
      },
      "outputs": [],
      "source": [
        "# Create the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(59,)),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    #tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
        "    #tf.keras.layers.Dense(units=2, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhIZSNqIbptU",
        "outputId": "6704634e-d2ec-4d59-d0be-3b38aca03572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3882 - accuracy: 0.8279 - val_loss: 0.3481 - val_accuracy: 0.8514\n",
            "Epoch 2/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3451 - accuracy: 0.8510 - val_loss: 0.3306 - val_accuracy: 0.8581\n",
            "Epoch 3/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3286 - accuracy: 0.8602 - val_loss: 0.3369 - val_accuracy: 0.8647\n",
            "Epoch 4/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8654 - val_loss: 0.3125 - val_accuracy: 0.8675\n",
            "Epoch 5/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3097 - accuracy: 0.8679 - val_loss: 0.3076 - val_accuracy: 0.8701\n",
            "Epoch 6/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3036 - accuracy: 0.8707 - val_loss: 0.3032 - val_accuracy: 0.8711\n",
            "Epoch 7/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2984 - accuracy: 0.8725 - val_loss: 0.3020 - val_accuracy: 0.8761\n",
            "Epoch 8/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2941 - accuracy: 0.8758 - val_loss: 0.3069 - val_accuracy: 0.8672\n",
            "Epoch 9/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2910 - accuracy: 0.8768 - val_loss: 0.2952 - val_accuracy: 0.8751\n",
            "Epoch 10/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2866 - accuracy: 0.8780 - val_loss: 0.2830 - val_accuracy: 0.8850\n",
            "Epoch 11/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2826 - accuracy: 0.8800 - val_loss: 0.2932 - val_accuracy: 0.8785\n",
            "Epoch 12/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.8803 - val_loss: 0.2966 - val_accuracy: 0.8760\n",
            "Epoch 13/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2782 - accuracy: 0.8811 - val_loss: 0.2910 - val_accuracy: 0.8764\n",
            "Epoch 14/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2769 - accuracy: 0.8821 - val_loss: 0.2818 - val_accuracy: 0.8839\n",
            "Epoch 15/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2746 - accuracy: 0.8837 - val_loss: 0.2811 - val_accuracy: 0.8837\n",
            "Epoch 16/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2739 - accuracy: 0.8836 - val_loss: 0.2927 - val_accuracy: 0.8802\n",
            "Epoch 17/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2720 - accuracy: 0.8845 - val_loss: 0.2845 - val_accuracy: 0.8827\n",
            "Epoch 18/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2700 - accuracy: 0.8853 - val_loss: 0.2986 - val_accuracy: 0.8746\n",
            "Epoch 19/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.8854 - val_loss: 0.2801 - val_accuracy: 0.8847\n",
            "Epoch 20/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2675 - accuracy: 0.8863 - val_loss: 0.2906 - val_accuracy: 0.8775\n",
            "Epoch 21/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2663 - accuracy: 0.8876 - val_loss: 0.2821 - val_accuracy: 0.8836\n",
            "Epoch 22/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2631 - accuracy: 0.8887 - val_loss: 0.2818 - val_accuracy: 0.8846\n",
            "Epoch 23/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2644 - accuracy: 0.8881 - val_loss: 0.2917 - val_accuracy: 0.8804\n",
            "Epoch 24/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2630 - accuracy: 0.8886 - val_loss: 0.2800 - val_accuracy: 0.8825\n",
            "Epoch 25/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.8906 - val_loss: 0.2969 - val_accuracy: 0.8769\n",
            "Epoch 26/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2582 - accuracy: 0.8902 - val_loss: 0.2850 - val_accuracy: 0.8793\n",
            "Epoch 27/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2584 - accuracy: 0.8901 - val_loss: 0.2869 - val_accuracy: 0.8800\n",
            "Epoch 28/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2551 - accuracy: 0.8909 - val_loss: 0.2866 - val_accuracy: 0.8792\n",
            "Epoch 29/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2549 - accuracy: 0.8915 - val_loss: 0.2923 - val_accuracy: 0.8780\n",
            "Epoch 30/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2531 - accuracy: 0.8918 - val_loss: 0.2926 - val_accuracy: 0.8799\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78bdb5f85ea0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AB5nIFjcg5j",
        "outputId": "867fb1c2-ac50-44e7-a0fe-2c5a400fe645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 949us/step\n",
            "Accuracy: 0.8799\n",
            "Confusion Matrix:\n",
            "-----------------\n",
            "True Positives  | 4659\n",
            "False Positives | 454\n",
            "True Negatives  | 4140\n",
            "False Negatives | 747\n",
            "-----------------\n",
            "Accuracy: 0.8799\n",
            "Precision: 0.9012\n",
            "Recall: 0.8471\n",
            "F1-Score: 0.8733\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "y_pred_binary = np.array(y_pred_binary)\n",
        "\n",
        "\n",
        "# Calculate the true positives, false positives, true negatives, and false negatives\n",
        "\n",
        "true_positives = np.sum((y_pred_binary == 0) & (y_test == 0))\n",
        "false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))\n",
        "true_negatives = np.sum((y_pred_binary == 1) & (y_test == 1))\n",
        "false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))\n",
        "\n",
        "# Create the table\n",
        "table = [\n",
        "    [\"True Positives\", true_positives],\n",
        "    [\"False Positives\", false_positives],\n",
        "    [\"True Negatives\", true_negatives],\n",
        "    [\"False Negatives\", false_negatives]\n",
        "]\n",
        "\n",
        "# Calculate the maximum width of the first column\n",
        "max_width = max(len(row[0]) for row in table)\n",
        "\n",
        "# Print the table\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"-----------------\")\n",
        "for row in table:\n",
        "    print(f\"{row[0]:<{max_width}} | {row[1]}\")\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "precision = precision_score(y_test, y_pred_binary)\n",
        "recall = recall_score(y_test, y_pred_binary)\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"-----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PCA"
      ],
      "metadata": {
        "id": "xu01TPzngkKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the first column\n",
        "\n",
        "shuffled_df.drop(shuffled_df.columns[0], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Performing PCA\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "data_df = shuffled_df.iloc[:, :-1]\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_df)\n",
        "\n",
        "# Specify the number of components you want to keep\n",
        "n_components = 39  # Choose an appropriate number\n",
        "\n",
        "# Create a PCA instance and fit it to your data\n",
        "pca = PCA(n_components=n_components)\n",
        "data_pca = pca.fit_transform(data_scaled)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance Ratios:\", explained_variance)\n",
        "\n",
        "# Create a DataFrame with named columns\n",
        "naming = [f'Feature {i+1}' for i in range(n_components)]\n",
        "pca_df = pd.DataFrame(data_pca, columns=naming)\n",
        "\n",
        "pca_df['type'] = shuffled_df.iloc[:, -1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7MgRvmP4Po0",
        "outputId": "1f83c736-f992-498f-e3b7-77906ebcce2f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance Ratios: [0.24695374 0.12127869 0.11172795 0.05937472 0.0448849  0.0379069\n",
            " 0.03340872 0.03188789 0.0306313  0.03003688 0.02980521 0.02775933\n",
            " 0.0266646  0.02314452 0.02150351 0.01816804 0.01374065 0.01011962\n",
            " 0.0098077  0.00899829 0.00822498 0.00734627 0.00664709 0.00556507\n",
            " 0.00510818 0.00478205 0.00409231 0.00310995 0.00245384 0.00232272\n",
            " 0.00218816 0.00166109 0.00146574 0.0012813  0.0011414  0.00104587\n",
            " 0.00084419 0.00059703 0.00049271]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d35435-2084-4097-acfd-319f378dcc45",
        "id": "jasYqozZgkKy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (60606, 39)\n",
            "y_train shape: (60606,)\n",
            "X_test shape: (10000, 39)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Extract features (X) and labels (y) for the entire dataset\n",
        "X_pca = pca_df.iloc[:, 0:n_components]  # Features from columns 0 to n_components\n",
        "y_pca = pca_df.iloc[:, n_components]    # Labels from the (n_components+1)th column\n",
        "\n",
        "# Split the data into training and test sets\n",
        "pcaX_train, pcaX_test, pcaY_train, pcaY_test = train_test_split(X_pca, y_pca, test_size=10000, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting datasets\n",
        "print(\"X_train shape:\", pcaX_train.shape)\n",
        "print(\"y_train shape:\", pcaY_train.shape)\n",
        "print(\"X_test shape:\", pcaX_test.shape)\n",
        "print(\"y_test shape:\", pcaY_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oaJWPb4FgkKy"
      },
      "outputs": [],
      "source": [
        "# Create the CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(n_components,)),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    #tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
        "    #tf.keras.layers.Dense(units=2, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de8cc40-4604-4112-c5ed-90aca45c0b7d",
        "id": "rNxV7sdcgkKz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3696 - accuracy: 0.8379 - val_loss: 0.3482 - val_accuracy: 0.8522\n",
            "Epoch 2/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3372 - accuracy: 0.8549 - val_loss: 0.3398 - val_accuracy: 0.8544\n",
            "Epoch 3/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3274 - accuracy: 0.8577 - val_loss: 0.3383 - val_accuracy: 0.8547\n",
            "Epoch 4/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3206 - accuracy: 0.8623 - val_loss: 0.3302 - val_accuracy: 0.8582\n",
            "Epoch 5/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3133 - accuracy: 0.8653 - val_loss: 0.3281 - val_accuracy: 0.8614\n",
            "Epoch 6/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.3066 - accuracy: 0.8672 - val_loss: 0.3186 - val_accuracy: 0.8642\n",
            "Epoch 7/30\n",
            "947/947 [==============================] - 3s 3ms/step - loss: 0.3003 - accuracy: 0.8706 - val_loss: 0.3231 - val_accuracy: 0.8644\n",
            "Epoch 8/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2945 - accuracy: 0.8734 - val_loss: 0.3168 - val_accuracy: 0.8675\n",
            "Epoch 9/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2894 - accuracy: 0.8771 - val_loss: 0.3210 - val_accuracy: 0.8628\n",
            "Epoch 10/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2847 - accuracy: 0.8782 - val_loss: 0.3188 - val_accuracy: 0.8638\n",
            "Epoch 11/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2800 - accuracy: 0.8807 - val_loss: 0.3135 - val_accuracy: 0.8671\n",
            "Epoch 12/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2755 - accuracy: 0.8833 - val_loss: 0.3132 - val_accuracy: 0.8683\n",
            "Epoch 13/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2712 - accuracy: 0.8847 - val_loss: 0.3126 - val_accuracy: 0.8695\n",
            "Epoch 14/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2675 - accuracy: 0.8862 - val_loss: 0.3172 - val_accuracy: 0.8647\n",
            "Epoch 15/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2628 - accuracy: 0.8889 - val_loss: 0.3166 - val_accuracy: 0.8671\n",
            "Epoch 16/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2605 - accuracy: 0.8904 - val_loss: 0.3247 - val_accuracy: 0.8658\n",
            "Epoch 17/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2572 - accuracy: 0.8930 - val_loss: 0.3192 - val_accuracy: 0.8657\n",
            "Epoch 18/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2530 - accuracy: 0.8942 - val_loss: 0.3333 - val_accuracy: 0.8643\n",
            "Epoch 19/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2503 - accuracy: 0.8950 - val_loss: 0.3304 - val_accuracy: 0.8616\n",
            "Epoch 20/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2463 - accuracy: 0.8978 - val_loss: 0.3453 - val_accuracy: 0.8606\n",
            "Epoch 21/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2433 - accuracy: 0.8990 - val_loss: 0.3335 - val_accuracy: 0.8642\n",
            "Epoch 22/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2404 - accuracy: 0.8994 - val_loss: 0.3280 - val_accuracy: 0.8666\n",
            "Epoch 23/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2372 - accuracy: 0.9012 - val_loss: 0.3301 - val_accuracy: 0.8666\n",
            "Epoch 24/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2340 - accuracy: 0.9029 - val_loss: 0.3322 - val_accuracy: 0.8646\n",
            "Epoch 25/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2325 - accuracy: 0.9040 - val_loss: 0.3367 - val_accuracy: 0.8654\n",
            "Epoch 26/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2289 - accuracy: 0.9051 - val_loss: 0.3460 - val_accuracy: 0.8637\n",
            "Epoch 27/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2267 - accuracy: 0.9058 - val_loss: 0.3380 - val_accuracy: 0.8639\n",
            "Epoch 28/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2230 - accuracy: 0.9073 - val_loss: 0.3463 - val_accuracy: 0.8615\n",
            "Epoch 29/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2205 - accuracy: 0.9087 - val_loss: 0.3458 - val_accuracy: 0.8597\n",
            "Epoch 30/30\n",
            "947/947 [==============================] - 2s 2ms/step - loss: 0.2187 - accuracy: 0.9100 - val_loss: 0.3550 - val_accuracy: 0.8592\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78bdb0923b80>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(pcaX_train, pcaY_train, epochs=30, batch_size=64, validation_data=(pcaX_test, pcaY_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45850db4-9607-4f5c-d7a1-c9df1a4ad1af",
        "id": "p8B6LVOggkKz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 885us/step\n",
            "Accuracy: 0.8592\n",
            "Confusion Matrix:\n",
            "-----------------\n",
            "True Positives  | 4293\n",
            "False Positives | 716\n",
            "True Negatives  | 4299\n",
            "False Negatives | 692\n",
            "-----------------\n",
            "Accuracy: 0.8592\n",
            "Precision: 0.8572\n",
            "Recall: 0.8614\n",
            "F1-Score: 0.8593\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = model.predict(pcaX_test)\n",
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred]\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(pcaY_test, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "y_pred_binary = np.array(y_pred_binary)\n",
        "\n",
        "\n",
        "# Calculate the true positives, false positives, true negatives, and false negatives\n",
        "\n",
        "true_positives = np.sum((y_pred_binary == 0) & (pcaY_test == 0))\n",
        "false_positives = np.sum((y_pred_binary == 1) & (pcaY_test == 0))\n",
        "true_negatives = np.sum((y_pred_binary == 1) & (pcaY_test == 1))\n",
        "false_negatives = np.sum((y_pred_binary == 0) & (pcaY_test == 1))\n",
        "\n",
        "# Create the table\n",
        "table = [\n",
        "    [\"True Positives\", true_positives],\n",
        "    [\"False Positives\", false_positives],\n",
        "    [\"True Negatives\", true_negatives],\n",
        "    [\"False Negatives\", false_negatives]\n",
        "]\n",
        "\n",
        "# Calculate the maximum width of the first column\n",
        "max_width = max(len(row[0]) for row in table)\n",
        "\n",
        "# Print the table\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"-----------------\")\n",
        "for row in table:\n",
        "    print(f\"{row[0]:<{max_width}} | {row[1]}\")\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(pcaY_test, y_pred_binary)\n",
        "precision = precision_score(pcaY_test, y_pred_binary)\n",
        "recall = recall_score(pcaY_test, y_pred_binary)\n",
        "f1 = f1_score(pcaY_test, y_pred_binary)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"-----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BayfR4lpm7Dr"
      },
      "source": [
        "## Using Randomforest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PCA"
      ],
      "metadata": {
        "id": "828ZApVzDkQd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hEIzFybpnwW3"
      },
      "outputs": [],
      "source": [
        "# Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will find best hyperparameters for Randomforest classifier which depends on our data."
      ],
      "metadata": {
        "id": "w4F5E5vkCrp-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mFhBApFnnJX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# This will take some time to run.\n",
        "\n",
        "param_dist = {'n_estimators': randint(10,100),\n",
        "              'max_depth': randint(5,20)}\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Use random search to find the best hyperparameters\n",
        "rand_search = RandomizedSearchCV(rf,\n",
        "                                 param_distributions = param_dist,\n",
        "                                 n_iter=5,\n",
        "                                 cv=5)\n",
        "\n",
        "# Fit the random search object to the data\n",
        "rand_search.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ILrWuUR6n01m",
        "outputId": "492499c8-38d1-4c3d-ad7c-c4c24ec40142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_depth': 19, 'n_estimators': 98}\n"
          ]
        }
      ],
      "source": [
        "# Create a variable for the best model\n",
        "best_rf = rand_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:',  rand_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "O-qtRwF-nBY7",
        "outputId": "2cc0a8f3-6d5c-437b-abd8-593ac37309f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=15, n_estimators=75, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, n_estimators=75, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, n_estimators=75, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Create and Train the RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=75,  max_depth=15, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "K4fIacgA4XNP"
      },
      "outputs": [],
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRnWpUfK7dp5",
        "outputId": "a08665dc-5eea-48b3-a01c-35ccd149ee31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8633\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.87      5113\n",
            "           1       0.87      0.84      0.86      4887\n",
            "\n",
            "    accuracy                           0.86     10000\n",
            "   macro avg       0.86      0.86      0.86     10000\n",
            "weighted avg       0.86      0.86      0.86     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tmFvsYiDg0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PCA"
      ],
      "metadata": {
        "id": "X7bDI8fhDxt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will find best hyperparameters for Randomforest classifier which depends on our data."
      ],
      "metadata": {
        "id": "GXDk9isnDoZ4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "msLAC8KGDoZ4",
        "outputId": "f9d698d0-0774-4b84-9aad-6a4654e1f1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
              "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf53310>,\n",
              "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf52a40>})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf53310&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf52a40&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
              "                   param_distributions={&#x27;max_depth&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf53310&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x78bdacf52a40&gt;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\n",
        "# This will take some time to run.\n",
        "\n",
        "param_dist = {'n_estimators': randint(10,100),\n",
        "              'max_depth': randint(5,20)}\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Use random search to find the best hyperparameters\n",
        "rand_search = RandomizedSearchCV(rf,\n",
        "                                 param_distributions = param_dist,\n",
        "                                 n_iter=5,\n",
        "                                 cv=5)\n",
        "\n",
        "# Fit the random search object to the data\n",
        "rand_search.fit(pcaX_train, pcaY_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de09bc2-b223-449f-833d-d01236960bd8",
        "id": "0hHsEWhdDoZ4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'max_depth': 17, 'n_estimators': 87}\n"
          ]
        }
      ],
      "source": [
        "# Create a variable for the best model\n",
        "best_rf = rand_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:',  rand_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "17ff0697-b4a8-4458-fb67-85e37a636a91",
        "id": "7BH28J1pDoZ4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=17, n_estimators=87, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=17, n_estimators=87, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=17, n_estimators=87, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Create and Train the RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=87,  max_depth=17, random_state=42)\n",
        "model.fit(pcaX_train , pcaY_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TuBiVI0rDoZ5"
      },
      "outputs": [],
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(pcaX_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f1793f-1feb-4e88-e2cb-467ae1dd4e94",
        "id": "lq0ujHiBDoZ5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8516\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.88      0.86      5009\n",
            "           1       0.87      0.82      0.85      4991\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model\n",
        "accuracy = accuracy_score(pcaY_test, y_pred)\n",
        "report = classification_report(pcaY_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GsUxgoP-c79"
      },
      "source": [
        "## Using XgBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Without PCA"
      ],
      "metadata": {
        "id": "cdi9i46JGtcB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isv-roAZqVCG"
      },
      "source": [
        "Now, we will find the optimum parameters. This will take some time to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_jyiTxt-cL1"
      },
      "outputs": [],
      "source": [
        "# Define the parameter distributions for randomized search\n",
        "param_dist = {\n",
        "    'objective': ['binary:logistic'],\n",
        "    'eval_metric': ['logloss'],\n",
        "    'learning_rate': [0.1],\n",
        "    'max_depth': [5,7,6,8],\n",
        "    'reg_alpha': [0.007, 0.1, 1.0, 10.0, 0.01, 0.001],\n",
        "    'reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
        "    'gamma': [0, 0.1, 0.5, 1.0, 0.01, 0.6]\n",
        "}\n",
        "\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "xgb_model1 = xgb.XGBClassifier()\n",
        "\n",
        "# Perform randomized search with cross-validation\n",
        "random_search1 = RandomizedSearchCV(xgb_model1, param_dist, n_iter=10, scoring='accuracy', cv=5)\n",
        "random_search1.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameter values and the corresponding model\n",
        "best_params = random_search1.best_params_\n",
        "best_model = random_search1.best_estimator_\n",
        "\n",
        "# Print the best parameter values\n",
        "print(\"Best Parameter Values:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Train the final model on the entire dataset using the best parameters\n",
        "final_model = xgb.XGBClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI69boIoqaDG"
      },
      "source": [
        "Training XgBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "08nRomGSpVmL"
      },
      "outputs": [],
      "source": [
        "# Convert the data into DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "\n",
        "# Set the XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 8,\n",
        "    'reg_alpha': 0.01,\n",
        "    'reg_lambda': 0.1,\n",
        "    'gamma': 0.5\n",
        "}\n",
        "\n",
        "\n",
        "# Train the XGBoost model\n",
        "num_rounds = 100\n",
        "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "# Obtain predicted probabilities for the positive class\n",
        "y_pred_proba = xgb_model.predict(dtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zVGbTIMapw8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdc1f95-ca38-456a-906f-d9005812e495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8795\n",
            "Confusion Matrix:\n",
            "-----------------\n",
            "True Positives  | 4595\n",
            "False Positives | 518\n",
            "True Negatives  | 4200\n",
            "False Negatives | 687\n",
            "-----------------\n",
            "Accuracy: 0.8795\n",
            "Precision: 0.8902\n",
            "Recall: 0.8594\n",
            "F1-Score: 0.8745\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "y_pred_binary = np.array(y_pred_binary)\n",
        "\n",
        "\n",
        "# Calculate the true positives, false positives, true negatives, and false negatives\n",
        "\n",
        "true_positives = np.sum((y_pred_binary == 0) & (y_test == 0))\n",
        "false_positives = np.sum((y_pred_binary == 1) & (y_test == 0))\n",
        "true_negatives = np.sum((y_pred_binary == 1) & (y_test == 1))\n",
        "false_negatives = np.sum((y_pred_binary == 0) & (y_test == 1))\n",
        "\n",
        "# Create the table\n",
        "table = [\n",
        "    [\"True Positives\", true_positives],\n",
        "    [\"False Positives\", false_positives],\n",
        "    [\"True Negatives\", true_negatives],\n",
        "    [\"False Negatives\", false_negatives]\n",
        "]\n",
        "\n",
        "# Calculate the maximum width of the first column\n",
        "max_width = max(len(row[0]) for row in table)\n",
        "\n",
        "# Print the table\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"-----------------\")\n",
        "for row in table:\n",
        "    print(f\"{row[0]:<{max_width}} | {row[1]}\")\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "precision = precision_score(y_test, y_pred_binary)\n",
        "recall = recall_score(y_test, y_pred_binary)\n",
        "f1 = f1_score(y_test, y_pred_binary)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"-----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With PCA"
      ],
      "metadata": {
        "id": "K8nW-qW2GxgU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9LA9LymGxgV"
      },
      "source": [
        "Finding the optimum parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "4zmuTn9tGxgV",
        "outputId": "74cadde4-e322-47de-9901-8a4ca255664d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameter Values:\n",
            "reg_lambda: 0.01\n",
            "reg_alpha: 0.001\n",
            "objective: binary:logistic\n",
            "max_depth: 7\n",
            "learning_rate: 0.1\n",
            "gamma: 0.6\n",
            "eval_metric: logloss\n",
            "Best Model Accuracy: 0.8545\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, gamma=0.6, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=0.6, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=0.6, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Define the parameter distributions for randomized search\n",
        "param_dist = {\n",
        "    'objective': ['binary:logistic'],\n",
        "    'eval_metric': ['logloss'],\n",
        "    'learning_rate': [0.1],\n",
        "    'max_depth': [5,7,6,8],\n",
        "    'reg_alpha': [0.007, 0.1, 1.0, 10.0, 0.01, 0.001],\n",
        "    'reg_lambda': [0.01, 0.1, 1.0, 10.0],\n",
        "    'gamma': [0, 0.1, 0.5, 1.0, 0.01, 0.6]\n",
        "}\n",
        "\n",
        "\n",
        "# Create an XGBoost classifier\n",
        "xgb_model1 = xgb.XGBClassifier()\n",
        "\n",
        "# Perform randomized search with cross-validation\n",
        "random_search1 = RandomizedSearchCV(xgb_model1, param_dist, n_iter=10, scoring='accuracy', cv=5)\n",
        "random_search1.fit(pcaX_train, pcaY_train)\n",
        "\n",
        "# Get the best parameter values and the corresponding model\n",
        "best_params = random_search1.best_params_\n",
        "best_model = random_search1.best_estimator_\n",
        "\n",
        "# Print the best parameter values\n",
        "print(\"Best Parameter Values:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_pred = best_model.predict(pcaX_test)\n",
        "accuracy = accuracy_score(pcaY_test, y_pred)\n",
        "print(f\"Best Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Train the final model on the entire dataset using the best parameters\n",
        "final_model = xgb.XGBClassifier(**best_params)\n",
        "final_model.fit(pcaX_train, pcaY_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_RH4bKnGxgV"
      },
      "source": [
        "Training XgBoost model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JEJRd6fgGxgV"
      },
      "outputs": [],
      "source": [
        "# Convert the data into DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(pcaX_train, label=pcaY_train)\n",
        "dtest = xgb.DMatrix(pcaX_test, label=pcaY_test)\n",
        "\n",
        "\n",
        "# Set the XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'learning_rate': 0.1,\n",
        "    'max_depth': 7,\n",
        "    'reg_alpha': 0.001,\n",
        "    'reg_lambda': 0.01,\n",
        "    'gamma': 0.6\n",
        "}\n",
        "\n",
        "\n",
        "# Train the XGBoost model\n",
        "num_rounds = 100\n",
        "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "# Obtain predicted probabilities for the positive class\n",
        "y_pred_proba = xgb_model.predict(dtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hnvTaOfGxgW",
        "outputId": "3954bb1f-ec8d-4512-8445-d387628b4d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8545\n",
            "Confusion Matrix:\n",
            "-----------------\n",
            "True Positives  | 4391\n",
            "False Positives | 618\n",
            "True Negatives  | 4154\n",
            "False Negatives | 837\n",
            "-----------------\n",
            "Accuracy: 0.8545\n",
            "Precision: 0.8705\n",
            "Recall: 0.8323\n",
            "F1-Score: 0.8510\n",
            "-----------------\n"
          ]
        }
      ],
      "source": [
        "y_pred_binary = [1 if p >= 0.5 else 0 for p in y_pred_proba]\n",
        "\n",
        "# Calculate accuracy of the model\n",
        "accuracy = accuracy_score(pcaY_test, y_pred_binary)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "y_pred_binary = np.array(y_pred_binary)\n",
        "\n",
        "\n",
        "# Calculate the true positives, false positives, true negatives, and false negatives\n",
        "\n",
        "true_positives = np.sum((y_pred_binary == 0) & (pcaY_test == 0))\n",
        "false_positives = np.sum((y_pred_binary == 1) & (pcaY_test == 0))\n",
        "true_negatives = np.sum((y_pred_binary == 1) & (pcaY_test == 1))\n",
        "false_negatives = np.sum((y_pred_binary == 0) & (pcaY_test == 1))\n",
        "\n",
        "# Create the table\n",
        "table = [\n",
        "    [\"True Positives\", true_positives],\n",
        "    [\"False Positives\", false_positives],\n",
        "    [\"True Negatives\", true_negatives],\n",
        "    [\"False Negatives\", false_negatives]\n",
        "]\n",
        "\n",
        "# Calculate the maximum width of the first column\n",
        "max_width = max(len(row[0]) for row in table)\n",
        "\n",
        "# Print the table\n",
        "print(\"Confusion Matrix:\")\n",
        "print(\"-----------------\")\n",
        "for row in table:\n",
        "    print(f\"{row[0]:<{max_width}} | {row[1]}\")\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(pcaY_test, y_pred_binary)\n",
        "precision = precision_score(pcaY_test, y_pred_binary)\n",
        "recall = recall_score(pcaY_test, y_pred_binary)\n",
        "f1 = f1_score(pcaY_test, y_pred_binary)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(\"-----------------\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BayfR4lpm7Dr",
        "8GsUxgoP-c79"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}